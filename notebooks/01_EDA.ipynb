{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - TikNep Dataset\n",
    "\n",
    "This notebook performs comprehensive EDA on the clean_annotated_4k.csv dataset containing Nepali comments.\n",
    "\n",
    "## Dataset Structure\n",
    "The dataset contains **4 different annotation tasks** on the same text corpus:\n",
    "\n",
    "1. Sentiment Analysis (SEN)** - Multi-class (Neutral=0, Negative=1, Positive=2)\n",
    "2. Hate and Offense Detection (HAO)** - Binary (Not Offensive=0, Offensive=1)\n",
    "3. Political Instance Detection (POL)** - Binary (Non-Political=0, Political=1)\n",
    "4. Multi-label Topic Classification** - 9 topics (PGS, FT, EYE, HBF, FR, EMP, BF, SW, DO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Define consistent color palette for all visualizations\n",
    "COLOR_PALETTE = {\n",
    "    # Sentiment Analysis (3 classes)\n",
    "    'sentiment': ['#5DADE2', '#E74C3C', '#52BE80'],  # Blue, Red, Green\n",
    "    \n",
    "    # Binary Classification (2 classes) - Consistent across HAO and POL\n",
    "    'binary_negative': '#5DADE2',  # Blue for negative/non-offensive/non-political\n",
    "    'binary_positive': '#E74C3C',  # Red for positive/offensive/political\n",
    "    \n",
    "    # Multi-label/General visualizations\n",
    "    'primary': '#5DADE2',      # Primary blue\n",
    "    'secondary': '#E74C3C',    # Secondary red\n",
    "    'tertiary': '#52BE80',     # Tertiary green\n",
    "    'accent': '#F39C12',       # Accent orange\n",
    "    \n",
    "    # Topic classification gradient (9 topics)\n",
    "    'topics': ['#5DADE2', '#3498DB', '#2E86C1', '#E74C3C', '#C0392B', \n",
    "               '#52BE80', '#27AE60', '#F39C12', '#D68910']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/clean_annotated_4k.csv')\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Total Rows: {df.shape[0]}\")\n",
    "print(f\"Total Columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Column Information:\")\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nData Types:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing Values:\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "print(f\"\\nTotal missing values: {missing_values.sum()}\")\n",
    "print(f\"Percentage of missing values: {(missing_values.sum() / (df.shape[0] * df.shape[1]) * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Duplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"Duplicate Text ID: {df['Text ID'].duplicated().sum()}\")\n",
    "print(f\"Duplicate Text: {df['Text'].duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_length'] = df['Text'].str.len()\n",
    "df['word_count'] = df['Text'].str.split().str.len()\n",
    "\n",
    "print(\"Text Length Statistics:\")\n",
    "print(df['text_length'].describe())\n",
    "print(\"\\nWord Count Statistics:\")\n",
    "print(df['word_count'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sentiment Analysis (SEN)\n",
    "\n",
    "**Task Type:** Multi-class Classification  \n",
    "**Classes:** 0 = Neutral, 1 = Negative, 2 = Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TASK 1: SENTIMENT ANALYSIS (SEN)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nTask Type: Multi-class Classification\")\n",
    "print(\"Classes: 0 = Neutral, 1 = Negative, 2 = Positive\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "sentiment_counts = df['SEN'].value_counts().sort_index()\n",
    "sentiment_map = {0: 'Neutral', 1: 'Negative', 2: 'Positive'}\n",
    "df['sentiment_label'] = df['SEN'].map(sentiment_map)\n",
    "\n",
    "print(\"\\nClass Distribution:\")\n",
    "for sentiment in [0, 1, 2]:\n",
    "    count = sentiment_counts[sentiment]\n",
    "    percentage = (count / len(df)) * 100\n",
    "    label = sentiment_map[sentiment]\n",
    "    print(f\"  Class {sentiment} ({label:>8}): {count:4d} samples ({percentage:5.2f}%)\")\n",
    "\n",
    "print(\"\\nClass Balance Analysis:\")\n",
    "majority_class = sentiment_counts.max()\n",
    "minority_class = sentiment_counts.min()\n",
    "imbalance_ratio = majority_class / minority_class\n",
    "print(f\"  Most frequent class:  {sentiment_counts.idxmax()} ({sentiment_map[sentiment_counts.idxmax()]}) - {majority_class} samples\")\n",
    "print(f\"  Least frequent class: {sentiment_counts.idxmin()} ({sentiment_map[sentiment_counts.idxmin()]}) - {minority_class} samples\")\n",
    "print(f\"  Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart\n",
    "sentiment_counts.plot(kind='bar', ax=axes[0], color=COLOR_PALETTE['sentiment'])\n",
    "axes[0].set_title('Sentiment Distribution', fontsize=16, fontweight='bold')\n",
    "axes[0].set_xlabel('Sentiment (0=Neutral, 1=Negative, 2=Positive)', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].set_xticklabels(['Neutral', 'Negative', 'Positive'], rotation=0)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(sentiment_counts):\n",
    "    axes[0].text(i, v + 30, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "labels = ['Neutral', 'Negative', 'Positive']\n",
    "axes[1].pie(sentiment_counts, labels=labels, colors=COLOR_PALETTE['sentiment'], autopct='%1.1f%%', \n",
    "            startangle=90, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "axes[1].set_title('Sentiment Distribution (%)', fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE COMMENTS BY CLASS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for sentiment in [0, 1, 2]:\n",
    "    sentiment_name = sentiment_map[sentiment]\n",
    "    print(f\"\\nClass {sentiment}: {sentiment_name.upper()}\")\n",
    "    print(\"-\"*80)\n",
    "    samples = df[df['SEN'] == sentiment]['Text'].head(5)\n",
    "    for i, comment in enumerate(samples, 1):\n",
    "        print(f\"  {i}. {comment}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hate and Offense Detection (HAO)\n",
    "\n",
    "**Task Type:** Binary Classification  \n",
    "**Classes:** 0 = Not Offensive, 1 = Offensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TASK 2: HATE AND OFFENSE DETECTION (HAO)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nTask Type: Binary Classification\")\n",
    "print(\"Classes: 0 = Not Offensive, 1 = Offensive\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "hao_counts = df['HAO'].value_counts().sort_index()\n",
    "hao_map = {0: 'Not Offensive', 1: 'Offensive'}\n",
    "\n",
    "print(\"\\nClass Distribution:\")\n",
    "for hao_class in [0, 1]:\n",
    "    count = hao_counts[hao_class]\n",
    "    percentage = (count / len(df)) * 100\n",
    "    label = hao_map[hao_class]\n",
    "    print(f\"  Class {hao_class} ({label:>14}): {count:4d} samples ({percentage:5.2f}%)\")\n",
    "\n",
    "print(\"\\nClass Balance Analysis:\")\n",
    "majority_class = hao_counts.max()\n",
    "minority_class = hao_counts.min()\n",
    "imbalance_ratio = majority_class / minority_class\n",
    "print(f\"  Most frequent class:  {hao_counts.idxmax()} ({hao_map[hao_counts.idxmax()]}) - {majority_class} samples\")\n",
    "print(f\"  Least frequent class: {hao_counts.idxmin()} ({hao_map[hao_counts.idxmin()]}) - {minority_class} samples\")\n",
    "print(f\"  Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart\n",
    "colors_hao = [COLOR_PALETTE['binary_negative'], COLOR_PALETTE['binary_positive']]\n",
    "hao_counts.plot(kind='bar', ax=axes[0], color=colors_hao)\n",
    "axes[0].set_title('Hate and Offense Distribution', fontsize=16, fontweight='bold')\n",
    "axes[0].set_xlabel('Class (0=Not Offensive, 1=Offensive)', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].set_xticklabels(['Not Offensive', 'Offensive'], rotation=0)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(hao_counts):\n",
    "    axes[0].text(i, v + 50, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "labels = ['Not Offensive', 'Offensive']\n",
    "axes[1].pie(hao_counts, labels=labels, colors=colors_hao, autopct='%1.1f%%', \n",
    "            startangle=90, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "axes[1].set_title('Hate and Offense Distribution (%)', fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE COMMENTS BY CLASS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for hao_class in [0, 1]:\n",
    "    label = hao_map[hao_class]\n",
    "    print(f\"\\nClass {hao_class}: {label.upper()}\")\n",
    "    print(\"-\"*80)\n",
    "    samples = df[df['HAO'] == hao_class]['Text'].head(5)\n",
    "    for i, comment in enumerate(samples, 1):\n",
    "        print(f\"  {i}. {comment}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Political Instance Detection (POL)\n",
    "\n",
    "**Task Type:** Binary Classification  \n",
    "**Classes:** 0 = Non-Political, 1 = Political"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TASK 3: POLITICAL INSTANCE DETECTION (POL)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nTask Type: Binary Classification\")\n",
    "print(\"Classes: 0 = Non-Political, 1 = Political\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "pol_counts = df['POL'].value_counts().sort_index()\n",
    "pol_map = {0: 'Non-Political', 1: 'Political'}\n",
    "\n",
    "print(\"\\nClass Distribution:\")\n",
    "for pol_class in [0, 1]:\n",
    "    count = pol_counts[pol_class]\n",
    "    percentage = (count / len(df)) * 100\n",
    "    label = pol_map[pol_class]\n",
    "    print(f\"  Class {pol_class} ({label:>14}): {count:4d} samples ({percentage:5.2f}%)\")\n",
    "\n",
    "print(\"\\nClass Balance Analysis:\")\n",
    "majority_class = pol_counts.max()\n",
    "minority_class = pol_counts.min()\n",
    "imbalance_ratio = majority_class / minority_class\n",
    "print(f\"  Most frequent class:  {pol_counts.idxmax()} ({pol_map[pol_counts.idxmax()]}) - {majority_class} samples\")\n",
    "print(f\"  Least frequent class: {pol_counts.idxmin()} ({pol_map[pol_counts.idxmin()]}) - {minority_class} samples\")\n",
    "print(f\"  Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart\n",
    "colors_pol = [COLOR_PALETTE['binary_negative'], COLOR_PALETTE['binary_positive']]\n",
    "pol_counts.plot(kind='bar', ax=axes[0], color=colors_pol)\n",
    "axes[0].set_title('Political Instance Distribution', fontsize=16, fontweight='bold')\n",
    "axes[0].set_xlabel('Class (0=Non-Political, 1=Political)', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].set_xticklabels(['Non-Political', 'Political'], rotation=0)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(pol_counts):\n",
    "    axes[0].text(i, v + 50, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "labels = ['Non-Political', 'Political']\n",
    "axes[1].pie(pol_counts, labels=labels, colors=colors_pol, autopct='%1.1f%%', \n",
    "            startangle=90, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "axes[1].set_title('Political Instance Distribution (%)', fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE COMMENTS BY CLASS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for pol_class in [0, 1]:\n",
    "    label = pol_map[pol_class]\n",
    "    print(f\"\\nClass {pol_class}: {label.upper()}\")\n",
    "    print(\"-\"*80)\n",
    "    samples = df[df['POL'] == pol_class]['Text'].head(5)\n",
    "    for i, comment in enumerate(samples, 1):\n",
    "        print(f\"  {i}. {comment}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-label Topic Classification\n",
    "\n",
    "**Task Type:** Multi-label Classification  \n",
    "**Number of Topics:** 9\n",
    "\n",
    "This section performs detailed exploratory data analysis on the **Multi-label Topic Classification** task from the TikNep dataset.\n",
    "\n",
    "### Topic Categories:\n",
    "\n",
    "1. **PGS**: Politics, Governance and Social Concern\n",
    "2. **FT**: Food and Travel\n",
    "3. **EYE**: Education, Youth and Employment\n",
    "4. **HBF**: Health, Beauty and Fitness\n",
    "5. **FR**: Family and Relationship\n",
    "6. **EMP**: Entertainment, Music and Pop Culture\n",
    "7. **BF**: Business and Finance\n",
    "8. **SW**: Spirituality and Well-being\n",
    "9. **DO**: Daily Diaries and Other Hobbies\n",
    "\n",
    "Each comment can have **multiple topic labels** (multi-label classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define topic columns\n",
    "topic_columns = {\n",
    "    'PGS': 'Politics, Governance and Social Concern',\n",
    "    'FT': 'Food and Travel',\n",
    "    'EYE': 'Education, Youth and Employment',\n",
    "    'HBF': 'Health, Beauty and Fitness',\n",
    "    'FR': 'Family and Relationship',\n",
    "    'EMP': 'Entertainment, Music and Pop Culture',\n",
    "    'BF': 'Business and Finance',\n",
    "    'SW': 'Spirituality and Well-being',\n",
    "    'DO': 'Daily Diaries and Other Hobbies'\n",
    "}\n",
    "\n",
    "topic_col_list = list(topic_columns.keys())\n",
    "\n",
    "print(\"Topic Categories:\")\n",
    "print(\"=\" * 80)\n",
    "for abbr, full_name in topic_columns.items():\n",
    "    print(f\"{abbr:5} : {full_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-label statistics\n",
    "# Calculate number of topics per comment\n",
    "df['num_topics'] = df[topic_col_list].sum(axis=1)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MULTI-LABEL STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTopic Distribution Summary:\")\n",
    "print(f\"  Average topics per comment: {df['num_topics'].mean():.2f}\")\n",
    "print(f\"  Median topics per comment:  {df['num_topics'].median():.0f}\")\n",
    "print(f\"  Standard deviation:         {df['num_topics'].std():.2f}\")\n",
    "print(f\"  Min topics per comment:     {df['num_topics'].min()}\")\n",
    "print(f\"  Max topics per comment:     {df['num_topics'].max()}\")\n",
    "\n",
    "print(\"\\nDistribution by Number of Topics:\")\n",
    "print(\"-\"*80)\n",
    "num_topics_dist = df['num_topics'].value_counts().sort_index()\n",
    "for num_topics, count in num_topics_dist.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"  {int(num_topics)} topic(s): {count:4d} samples ({percentage:5.2f}%)\")\n",
    "\n",
    "print(\"\\nMulti-label Analysis:\")\n",
    "print(\"-\"*80)\n",
    "no_topic = (df['num_topics'] == 0).sum()\n",
    "single_topic = (df['num_topics'] == 1).sum()\n",
    "multi_topic = (df['num_topics'] >= 2).sum()\n",
    "\n",
    "print(f\"  Comments with 0 topics:  {no_topic:4d} samples ({(no_topic/len(df)*100):5.2f}%)\")\n",
    "print(f\"  Comments with 1 topic:   {single_topic:4d} samples ({(single_topic/len(df)*100):5.2f}%)\")\n",
    "print(f\"  Comments with 2+ topics: {multi_topic:4d} samples ({(multi_topic/len(df)*100):5.2f}%)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution of number of topics per comment\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart\n",
    "num_topics_dist.plot(kind='bar', ax=axes[0], color=COLOR_PALETTE['primary'], edgecolor='black')\n",
    "axes[0].set_title('Distribution of Number of Topics per Comment', fontsize=16, fontweight='bold')\n",
    "axes[0].set_xlabel('Number of Topics', fontsize=12)\n",
    "axes[0].set_ylabel('Number of Comments', fontsize=12)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "\n",
    "for i, v in enumerate(num_topics_dist):\n",
    "    axes[0].text(i, v + 20, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "labels_pie = ['No topics', '1 topic', '2+ topics']\n",
    "sizes_pie = [no_topic, single_topic, multi_topic]\n",
    "colors_pie = [COLOR_PALETTE['primary'], COLOR_PALETTE['secondary'], COLOR_PALETTE['tertiary']]\n",
    "axes[1].pie(sizes_pie, labels=labels_pie, colors=colors_pie, autopct='%1.1f%%',\n",
    "           startangle=90, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "axes[1].set_title('Multi-label Distribution', fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic frequency distribution\n",
    "topic_counts = df[topic_col_list].sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"INDIVIDUAL TOPIC DISTRIBUTION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n{'Rank':<6} {'Topic':<6} {'Full Name':<50} {'Count':<10} {'Percentage'}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for rank, (topic_abbr, count) in enumerate(topic_counts.items(), 1):\n",
    "    percentage = (count / len(df)) * 100\n",
    "    full_name = topic_columns[topic_abbr]\n",
    "    print(f\"{rank:<6} {topic_abbr:<6} {full_name:<50} {count:<10} {percentage:5.2f}%\")\n",
    "\n",
    "# Calculate class imbalance\n",
    "max_count = topic_counts.max()\n",
    "min_count = topic_counts.min()\n",
    "imbalance_ratio = max_count / min_count\n",
    "\n",
    "print(\"\\nClass Balance Analysis:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"  Most frequent topic:  {topic_counts.index[0]} ({topic_columns[topic_counts.index[0]]}) - {topic_counts.iloc[0]} samples\")\n",
    "print(f\"  Least frequent topic: {topic_counts.index[-1]} ({topic_columns[topic_counts.index[-1]]}) - {topic_counts.iloc[-1]} samples\")\n",
    "print(f\"  Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Overall Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive summary\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE EDA SUMMARY - TikNep Dataset\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. DATASET OVERVIEW\")\n",
    "print(\"-\"*80)\n",
    "print(f\"   Total Comments:      {len(df):,}\")\n",
    "print(f\"   Total Features:      {df.shape[1]}\")\n",
    "print(f\"   Missing Values:      {df.isnull().sum().sum()}\")\n",
    "print(f\"   Duplicate Comments:  {df['Text'].duplicated().sum()}\")\n",
    "\n",
    "print(\"\\n2. SENTIMENT ANALYSIS (SEN)\")\n",
    "print(\"-\"*80)\n",
    "sentiment_counts_summary = df['SEN'].value_counts().sort_index()\n",
    "for sentiment in [0, 1, 2]:\n",
    "    count = sentiment_counts_summary[sentiment]\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"   Class {sentiment} ({sentiment_map[sentiment]:>8}): {count:,} samples ({percentage:.1f}%)\")\n",
    "sentiment_imbalance = sentiment_counts_summary.max() / sentiment_counts_summary.min()\n",
    "print(f\"   Imbalance Ratio: {sentiment_imbalance:.2f}:1\")\n",
    "\n",
    "print(\"\\n3.  HATE AND OFFENSE DETECTION (HAO)\")\n",
    "print(\"-\"*80)\n",
    "hao_counts_summary = df['HAO'].value_counts().sort_index()\n",
    "for hao_class in [0, 1]:\n",
    "    label = hao_map[hao_class]\n",
    "    count = hao_counts_summary[hao_class]\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"   Class {hao_class} ({label:>14}): {count:,} samples ({percentage:.1f}%)\")\n",
    "hao_imbalance = hao_counts_summary.max() / hao_counts_summary.min()\n",
    "print(f\"   Imbalance Ratio: {hao_imbalance:.2f}:1\")\n",
    "\n",
    "print(\"\\n4. POLITICAL INSTANCE DETECTION (POL)\")\n",
    "print(\"-\"*80)\n",
    "pol_counts_summary = df['POL'].value_counts().sort_index()\n",
    "for pol_class in [0, 1]:\n",
    "    label = pol_map[pol_class]\n",
    "    count = pol_counts_summary[pol_class]\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"   Class {pol_class} ({label:>14}): {count:,} samples ({percentage:.1f}%)\")\n",
    "pol_imbalance = pol_counts_summary.max() / pol_counts_summary.min()\n",
    "print(f\"   Imbalance Ratio: {pol_imbalance:.2f}:1\")\n",
    "\n",
    "print(\"\\n5. MULTI-LABEL TOPIC CLASSIFICATION\")\n",
    "print(\"-\"*80)\n",
    "print(f\"   Average topics per comment: {df['num_topics'].mean():.2f}\")\n",
    "print(f\"   Comments with 0 topics:     {(df['num_topics'] == 0).sum():,} samples\")\n",
    "print(f\"   Comments with 1 topic:      {(df['num_topics'] == 1).sum():,} samples\")\n",
    "print(f\"   Comments with 2+ topics:    {(df['num_topics'] >= 2).sum():,} samples\")\n",
    "print(f\"   Max topics on a comment:    {df['num_topics'].max()}\")\n",
    "print(\"\\n   Top 3 Topics:\")\n",
    "top_3_topics = df[topic_col_list].sum().sort_values(ascending=False).head(3)\n",
    "for topic_abbr, count in top_3_topics.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"     {topic_abbr}: {count:,} samples ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\n6. TEXT CHARACTERISTICS\")\n",
    "print(\"-\"*80)\n",
    "print(f\"   Average text length:  {df['text_length'].mean():.1f} characters\")\n",
    "print(f\"   Average word count:   {df['word_count'].mean():.1f} words\")\n",
    "print(f\"   Shortest comment:     {df['text_length'].min()} characters\")\n",
    "print(f\"   Longest comment:      {df['text_length'].max()} characters\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
